{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Stemming\n",
    "Stemming is the process of reducing a word to its word stem that affixes to suffixes and prefixes or to the roots of words known as a lemma. Stemming is important in natural language understanding (NLU) and natural language processing (NLP)."
   ],
   "id": "6863e46fb8e9f352"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-22T03:07:37.413209Z",
     "start_time": "2026-01-22T03:07:37.408288Z"
    }
   },
   "source": [
    "## Classification Problem\n",
    "## Comments of product is a positive review or negative review\n",
    "## Reviews----> eating, eat,eaten [going,gone,goes]--->go\n",
    "\n",
    "words=[\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"history\",\"finally\",\"finalized\"]"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T03:07:37.426821Z",
     "start_time": "2026-01-22T03:07:37.424955Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e2b615aefe69fe69",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### PorterStemmer",
   "id": "504a5b1a4b8bd376"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T03:07:37.440633Z",
     "start_time": "2026-01-22T03:07:37.437119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemming = PorterStemmer()\n",
    "for word in words:\n",
    "    print(word+\"----->\"+stemming.stem(word))\n"
   ],
   "id": "f7c46fe7ee4f79b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating----->eat\n",
      "eats----->eat\n",
      "eaten----->eaten\n",
      "writing----->write\n",
      "writes----->write\n",
      "programming----->program\n",
      "programs----->program\n",
      "history----->histori\n",
      "finally----->final\n",
      "finalized----->final\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T03:07:37.466463Z",
     "start_time": "2026-01-22T03:07:37.460295Z"
    }
   },
   "cell_type": "code",
   "source": "stemming.stem(\"Congratulations\")",
   "id": "809ddff68c4b9afc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T03:07:37.509376Z",
     "start_time": "2026-01-22T03:07:37.505725Z"
    }
   },
   "cell_type": "code",
   "source": "stemming.stem(\"sitting\")",
   "id": "3f89030e95da13f1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sit'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T03:07:37.526749Z",
     "start_time": "2026-01-22T03:07:37.524919Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "70abd9412f3e2d47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### RegexpStemmer class\n",
    "NLTK has RegexpStemmer class with the help of which we can easily implement Regular Expression Stemmer algorithms. It basically takes a single regular expression and removes any prefix or suffix that matches the expression. Let us see an example"
   ],
   "id": "63447ebd5b2579f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T03:07:37.545308Z",
     "start_time": "2026-01-22T03:07:37.542232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "rege_stemmer = RegexpStemmer(\"ing$|s$|ly$|able$\",min=4)\n",
    "for word in words:\n",
    "    print(word+\"----->\"+rege_stemmer.stem(word))\n"
   ],
   "id": "ed2b6fc995bf0a11",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating----->eat\n",
      "eats----->eat\n",
      "eaten----->eaten\n",
      "writing----->writ\n",
      "writes----->write\n",
      "programming----->programm\n",
      "programs----->program\n",
      "history----->history\n",
      "finally----->final\n",
      "finalized----->finalized\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T03:07:37.568585Z",
     "start_time": "2026-01-22T03:07:37.564738Z"
    }
   },
   "cell_type": "code",
   "source": "rege_stemmer.stem(\"writing\")\n",
   "id": "73cc14210ef0d1c9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'writ'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T03:07:37.587182Z",
     "start_time": "2026-01-22T03:07:37.583391Z"
    }
   },
   "cell_type": "code",
   "source": "rege_stemmer.stem(\"eating\")",
   "id": "f62eeb4921eb8d84",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T03:07:37.605086Z",
     "start_time": "2026-01-22T03:07:37.601511Z"
    }
   },
   "cell_type": "code",
   "source": "rege_stemmer.stem('ingeating')",
   "id": "b92ce42ae60349c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ingeat'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T03:07:37.617740Z",
     "start_time": "2026-01-22T03:07:37.615676Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b0b7a6d172e06fcc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Snowball Stemmer\n",
    "It is a stemming algorithm which is also known as the Porter2 stemming algorithm as it is a better version of the Porter Stemmer since some issues of it were fixed in this stemmer."
   ],
   "id": "f3ceafd0c8841bb9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T03:07:37.635464Z",
     "start_time": "2026-01-22T03:07:37.631288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snow_stemmer = SnowballStemmer(\"english\")\n",
    "for word in words:\n",
    "    print(word+\"----->\"+snow_stemmer.stem(word))"
   ],
   "id": "301069ea6c4a7708",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating----->eat\n",
      "eats----->eat\n",
      "eaten----->eaten\n",
      "writing----->write\n",
      "writes----->write\n",
      "programming----->program\n",
      "programs----->program\n",
      "history----->histori\n",
      "finally----->final\n",
      "finalized----->final\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T03:07:37.659637Z",
     "start_time": "2026-01-22T03:07:37.655779Z"
    }
   },
   "cell_type": "code",
   "source": "stemming.stem(\"fairly\"),stemming.stem(\"sportingly\")",
   "id": "3a621d09665b62f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T03:07:37.681859Z",
     "start_time": "2026-01-22T03:07:37.676817Z"
    }
   },
   "cell_type": "code",
   "source": "snow_stemmer.stem(\"fairly\"),snow_stemmer.stem(\"sportingly\")",
   "id": "c83559afb202fc3b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T03:07:37.700967Z",
     "start_time": "2026-01-22T03:07:37.696554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "snow_stemmer.stem('goes')\n",
    "'goe'\n"
   ],
   "id": "866b28f7a8bd5b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goe'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T03:07:37.722942Z",
     "start_time": "2026-01-22T03:07:37.718703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stemming.stem('goes')\n",
    "'goe'"
   ],
   "id": "5c6f4d3cfe4527f8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goe'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Wordnet Lemmatizer\n",
    "Lemmatization technique is like stemming. The output we will get after lemmatization is called ‘lemma’, which is a root word rather than root stem, the output of stemming. After lemmatization, we will be getting a valid word that means the same thing.\n",
    "\n",
    "NLTK provides WordNetLemmatizer class which is a thin wrapper around the wordnet corpus. This class uses morphy() function to the WordNet CorpusReader class to find a lemma. Let us understand it with an example −"
   ],
   "id": "9590f19a3c684355"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T03:07:55.293433Z",
     "start_time": "2026-01-22T03:07:55.287458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ],
   "id": "44c4def0d8cff847",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T03:07:56.253276Z",
     "start_time": "2026-01-22T03:07:56.249213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for word in words:\n",
    "    print(word + \"------>\" + lemmatizer.lemmatize(word, pos='v'))\n"
   ],
   "id": "9985dabe9a0c31c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating------>eat\n",
      "eats------>eat\n",
      "eaten------>eat\n",
      "writing------>write\n",
      "writes------>write\n",
      "programming------>program\n",
      "programs------>program\n",
      "history------>history\n",
      "finally------>finally\n",
      "finalized------>finalize\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T03:07:40.029518Z",
     "start_time": "2026-01-22T03:07:40.028074Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c54583f77ad44605",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
